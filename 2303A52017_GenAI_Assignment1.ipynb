{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52012/GenAI_2303A52012/blob/main/2303A52012_GenAI_A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# regression metrices"
      ],
      "metadata": {
        "id": "YweCGpEdUC2i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cieaIhOhQA2b"
      },
      "outputs": [],
      "source": [
        "y=[10,20,30,40,50]\n",
        "yp=[10.2,20.5,30.3,40.8,50.6]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## without lyb"
      ],
      "metadata": {
        "id": "K_YQ_nkif7OG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum=0\n",
        "for i in range(len(y)):\n",
        "    sum+=(y[i]-yp[i])**2\n",
        "mean_square_error=sum/len(y)\n",
        "print('the mean square error of the above data is: ',mean_square_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htg81I_rQEmH",
        "outputId": "1e9ef515-91dd-4880-92c3-ac898e60f79c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean square error of the above data is:  0.27599999999999947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum=0\n",
        "for i in range(len(y)):\n",
        "    sum+=abs(y[i]-yp[i])\n",
        "mean_abs_error=sum/len(y)\n",
        "print('the mean abs error of the above data is: ',mean_abs_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEiUfHu5QGWG",
        "outputId": "48b9e3d6-2c5c-4cf7-a530-260ee1324ff8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean abs error of the above data is:  0.4799999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('the root mean error of the above data is: ',(mean_square_error**0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNDeUc4pQIAW",
        "outputId": "fb72e152-c864-4b25-80ee-af6bcf44f780"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the root mean error of the above data is:  0.5253570214625474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## with lyb"
      ],
      "metadata": {
        "id": "3-hMcDNFgE1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "H4ndH-mMQcpY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y, yp)\n",
        "print('The Mean Squared Error is:', mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_hn1xMjQ18f",
        "outputId": "730882d1-2b28-4629-84ed-c4c8afca89a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Squared Error is: 0.27599999999999947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y, yp)\n",
        "print('The Mean Absolute Error is:', mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNrT8s6fQ-rq",
        "outputId": "4634a358-600d-4412-93b0-f17114a61abf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Absolute Error is: 0.4799999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = mse**0.5  # RMSE is the square root of MSE\n",
        "print('The Root Mean Squared Error is:', rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQdWt0_eRLBU",
        "outputId": "1ecf4b31-3d6d-4912-9f46-166168b9c2fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Root Mean Squared Error is: 0.5253570214625474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# classification metrices"
      ],
      "metadata": {
        "id": "UzeZFMiWT9Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "yact=[0,0,0,0,0,1,1,1,1,1,1,2,2,2,2,2]\n",
        "ypred=[0,0,1,1,2,2,0,1,1,1,2,0,2,1,1,2]"
      ],
      "metadata": {
        "id": "PeqF19kkUlnC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## without lyb"
      ],
      "metadata": {
        "id": "SkztYDyoUcIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for i in range(len(yact)):\n",
        "    l.append([yact[i],ypred[i]])\n",
        "print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80lyDlbkUfXR",
        "outputId": "09f2dc12-fb08-4c5f-d0b8-0db7ba970026"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0], [0, 0], [0, 1], [0, 1], [0, 2], [1, 2], [1, 0], [1, 1], [1, 1], [1, 1], [1, 2], [2, 0], [2, 2], [2, 1], [2, 1], [2, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yact_set=list(sorted(set(yact)))\n",
        "yact_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn1-yVFmkR8i",
        "outputId": "bffb3d00-b8bb-4bbb-b696-de7da02ce055"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm=[]\n",
        "for i in yact_set:\n",
        "  temp=[]\n",
        "  for j in yact_set:\n",
        "    temp.append(l.count([i,j]))\n",
        "  cm.append(temp)"
      ],
      "metadata": {
        "id": "oV0xvQTvki_W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"confusionmatrix of above data is:\\n\",np.array(cm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXKqWbO1VXW7",
        "outputId": "32a5861d-5186-4784-d2de-39e1a72b3cec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusionmatrix of above data is:\n",
            " [[2 2 1]\n",
            " [1 3 2]\n",
            " [1 2 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_precision_recall_f1(cm):\n",
        "    # Calculate the total number of data points outside of the loop\n",
        "    total = sum(sum(row) for row in cm)\n",
        "    num_classes = len(cm)\n",
        "    precision = [0] * num_classes\n",
        "    recall = [0] * num_classes\n",
        "    f1_score = [0] * num_classes  # Initialize F1-score list\n",
        "    tp_mat = []\n",
        "    fp_mat = []\n",
        "    fn_mat = []\n",
        "    tn_mat = []\n",
        "\n",
        "\n",
        "    for i in range(num_classes):  # Iterate over each class (rows)\n",
        "        # Calculate precision for class i\n",
        "        tp = cm[i][i]  # True Positives for class i\n",
        "        fp = 0\n",
        "        for j in range(num_classes):\n",
        "            if j != i:\n",
        "                fp += cm[j][i]  # False Positives for class i\n",
        "        if tp + fp != 0:  # Avoid division by zero\n",
        "            precision[i] = tp / (tp + fp)\n",
        "\n",
        "        # Calculate recall for class i\n",
        "        tp = cm[i][i]  # True Positives for class i\n",
        "        fn = 0\n",
        "        for j in range(num_classes):\n",
        "            if j != i:\n",
        "                fn += cm[i][j]  # False Negatives for class i\n",
        "        if tp + fn != 0:  # Avoid division by zero\n",
        "            recall[i] = tp / (tp + fn)\n",
        "\n",
        "        # Calculate F1-score for class i\n",
        "        if precision[i] + recall[i] != 0:  # Avoid division by zero\n",
        "            f1_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
        "\n",
        "        tp_mat.append(tp)\n",
        "        fp_mat.append(fp)\n",
        "        fn_mat.append(fn)\n",
        "        tn_mat.append(total - tp - fp - fn)  # Use the total calculated outside the loop\n",
        "\n",
        "    # Return total along with other metrics\n",
        "    return precision, recall, f1_score, tp_mat, fp_mat, fn_mat, tn_mat, total\n",
        "\n",
        "# Assuming 'cm' is defined as in your previous code\n",
        "precision_values, recall_values, f1_values, tp_mat, fp_mat, fn_mat, tn_mat, total = calculate_precision_recall_f1(cm)\n",
        "\n",
        "# Print results for each class\n",
        "for i in range(len(precision_values)):\n",
        "    print(f\"Class {i} - Precision: {precision_values[i]}, Recall: {recall_values[i]}, F1-Score: {f1_values[i]}\")\n",
        "\n",
        "# Print overall metrics\n",
        "print(f\"\\nOverall Accuracy: {np.sum(tp_mat)/total}\") # Using the calculated 'total' here\n",
        "print(f\"Overall Precision: {np.sum(tp_mat) / (np.sum(tp_mat) + np.sum(fp_mat))}\")\n",
        "print(f\"Overall Recall: {np.sum(tp_mat) / (np.sum(tp_mat) + np.sum(fn_mat)):.4f}\")\n",
        "print(f\"Overall F1-Score: {np.mean(f1_values)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "9LGz-aluZMmo",
        "outputId": "ebfa3d9f-a447-4e82-dce0-d35fb4eda1df"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'float' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-44e76f6e8f43>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Assuming 'cm' is defined as in your previous code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mprecision_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_precision_recall_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Print results for each class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-44e76f6e8f43>\u001b[0m in \u001b[0;36mcalculate_precision_recall_f1\u001b[0;34m(cm)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_precision_recall_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Calculate the total number of data points outside of the loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## with lyb"
      ],
      "metadata": {
        "id": "4eETeXIIUZeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(yact, ypred))\n",
        "\n",
        "# Classification Report (Precision, Recall, F1)\n",
        "print(\"Classification Report:\\n\", classification_report(yact, ypred))\n",
        "\n",
        "# Individual Metrics\n",
        "accuracy = accuracy_score(yact, ypred)\n",
        "precision = precision_score(yact, ypred, average='weighted')\n",
        "recall = recall_score(yact, ypred, average='weighted')\n",
        "f1 = f1_score(yact, ypred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbmiyYfVSTb4",
        "outputId": "66e4a09c-f32c-4d24-a82e-76962562290c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[2 2 1]\n",
            " [1 3 2]\n",
            " [1 2 2]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.40      0.44         5\n",
            "           1       0.43      0.50      0.46         6\n",
            "           2       0.40      0.40      0.40         5\n",
            "\n",
            "    accuracy                           0.44        16\n",
            "   macro avg       0.44      0.43      0.44        16\n",
            "weighted avg       0.44      0.44      0.44        16\n",
            "\n",
            "Accuracy: 0.4375\n",
            "Precision: 0.4419642857142857\n",
            "Recall: 0.4375\n",
            "F1-Score: 0.43696581196581197\n"
          ]
        }
      ]
    }
  ]
}